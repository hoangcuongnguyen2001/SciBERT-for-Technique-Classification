# SciBERT Fine-tuned for Cyber Attack Technique Classification
This is my repository of code and data for my Honours projects: **Analysing Technique Classification Performance of Cyber Threat Intelligence Extractors**. This is my training pipeline for SciBERT (a Large Language Model based on BERT): [SciBERT: A Pretrained Language Model for Scientific Text](https://arxiv.org/abs/1903.10676).

This Large Language Model is used to extract attack techniques from threat intelligence reports, as a basis for TRAM program: [TRAM](https://github.com/center-for-threat-informed-defense/tram) from Center of Threat-Informed Defense by MITRE Corporation. 

By training this model with a new dataset, from [Barbaraci and Natella, 2022](https://github.com/dessertlab/cti-to-mitre-with-nlp), rebalanced it with synthetic data generated by ChatGPT, and adjusting training epochs, we were able to improve the F1-score of TRAM by 7 percentage points compared to the original version of TRAM. 

The structure of our pipeline could be shown in this image (the pipeline number 4). ![image](https://github.com/user-attachments/assets/8db398da-5957-4e73-b22c-6d1f36c29b31)

The paper has been accepted in The Web Conference 2025, under the name of **Towards Effective Identification of Attack Techniques in Cyber Threat Intelligence Reports using Large Language Models**.
An update for this paper would be available soon, once it is camera-ready.

For further information about my own works, please look at my thesis here: (https://drive.google.com/file/d/1XVyrp7QPhTO1ETJA6rOYtpVwLV0XBY82/view?usp=sharing).
